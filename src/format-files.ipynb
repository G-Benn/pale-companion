{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.35'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gibson/wildbow-lookup'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is this?\n",
    "A Formatter to change the default content files produced by the scraper to a series of text files linked to their metadata. It will be converted a standalone script in the near future.\n",
    "\n",
    "## Input\n",
    "A folder of HTML files downloaded from the scraper.\n",
    "\n",
    "## Processing Steps\n",
    "1. Iterate over all HTML files generated from the scraper.\n",
    "2. Parse the HTML, pulling out the necessary metadata.\n",
    "3. Remove unnecessary mess like character PoV, chapter title, Previous/Next chapter, etc\n",
    "4. Write out as text a different verison of the file\n",
    "\n",
    "## Output\n",
    "A directory (parsed into a df for simple manipulation) containing:\n",
    "- A list of text files numbered by their chapter appearance\n",
    "- A metadata JSON containing the following information keyed on chapter Index\n",
    "    - ~~Chapter Number~~\n",
    "    - ~~Arc Number~~\n",
    "    - ~~Arc Title~~\n",
    "    - ~~Character Viewpoint~~\n",
    "    - Publish date (not available)\n",
    "    - ~~Interlude flag~~\n",
    "    - Series (to expand to other series as necessary)\n",
    "    - The plaintext\n",
    "        - No XML version\n",
    "        - No head\n",
    "        - No h1 title\n",
    "        - No floating previous / next chapter\n",
    "        - No interlude / viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_prefix = './content/'\n",
    "all_files = sorted([f for f in os.listdir(dir_prefix) if os.path.isfile(os.path.join(dir_prefix,f)) and f.endswith('.html')])\n",
    "# all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not caught: interude\n",
      "Not caught: mccauleigh sat in the chair in raymond’s office.  diffuse images moved around them, projected.  he had programs he could lean on that referenced marketing to certain age groups, calming colors, interests, and styles, then pull those together enough that there was something vaguely soothing and yet not distracting in regular motion, on monitors and projected surfaces.  he’d read the notes, checked with witnesses.\n",
      "Not caught:  \n",
      "Not caught: the alabaster doe endured an existence of paradoxes.  few things drove that home as much as her role here at the arena.  an architect of mercy paying witness to a fierce battle of strength.  john stiles leading his group of soldiers against the wolves of the ephemeral alpha, two very different sorts of hunter and fighter fighting viciously.  the first irony was that she was very well equipped to study what was happening.\n",
      "Not caught: cagerattler\n",
      "Not caught: the alabaster gave the signal.\n",
      "Not caught: the beorgmann used one hand to lift planks up to the y-divide of branches in a tree, balancing them there.  hand still upraised, he grabbed a branch, and lifted himself into the air, feet carrying more planks, rope, and a bucket filled with old-fashioned nails, long triangular wedges instead of straight posts with pointed ends and flat heads.\n",
      "Not caught: prologue\n"
     ]
    }
   ],
   "source": [
    "parsed_files = []\n",
    "for fname in all_files:\n",
    "    file_number = int(re.search(r'\\d+',fname).group())\n",
    "    # print(file_number)\n",
    "    with open(dir_prefix + fname) as fp:\n",
    "        soup = BeautifulSoup(fp,features='xml')\n",
    "\n",
    "    full_title = soup.title.string # Parse into metadata, etc\n",
    "    if re.search(r'Break \\d',full_title):\n",
    "        # Dealing with Break, which is a bit different\n",
    "        arc_name = 'Break'\n",
    "        arc_number = 13 # Since it takes place within Summer Break / 13\n",
    "        break_num =int(re.search(r'\\d',full_title).group())\n",
    "        chapter_number = f\"B{break_num}\" # Naming them Arc 13.bX\n",
    "    elif full_title == 'Summer Break':\n",
    "        # The last Chapter here has no numbers\n",
    "        arc_name = ' Summer Break'\n",
    "        arc_number = 13\n",
    "        chapter_number = 'end' # There's not a great way to do it otherwise imo\n",
    "    elif full_title == 'In Absentia 21.12':\n",
    "        arc_name = 'In Absentia'\n",
    "        arc_number = 21\n",
    "        chapter_number = 12\n",
    "    else:\n",
    "        split_title = full_title.split('–')\n",
    "        arc_name, number = split_title[0].strip(), split_title[1].strip()\n",
    "        if '.' in number:\n",
    "            number_to_split = number.split('.')\n",
    "        else:\n",
    "            # That Cherrypop interlude where things are misspelled\n",
    "            if number == '12a':\n",
    "                number_to_split = ('12','aa')\n",
    "        arc_number, chapter_number = number_to_split[0].strip(), number_to_split[1].strip()\n",
    "    # print(arc_name,arc_number, chapter_number)\n",
    "    perspective_or_interlude = soup.find('p').getText().lower()\n",
    "    decompose_flag = True\n",
    "    if 'interlude' in perspective_or_interlude:\n",
    "        chapter_type = 'Interlude' # Gotta check for that cherrypop interlude\n",
    "        viewpoint = perspective_or_interlude\n",
    "        # print(f\"Interlude: {viewpoint}\")\n",
    "    elif 'lucy' in perspective_or_interlude:\n",
    "        chapter_type = 'Lucy'\n",
    "        viewpoint = 'Lucy'\n",
    "    elif 'avery' in perspective_or_interlude:\n",
    "        chapter_type = 'Avery'\n",
    "        viewpoint = 'Avery'\n",
    "    elif 'verona' in perspective_or_interlude:\n",
    "        chapter_type = 'Verona'\n",
    "        viewpoint = 'Verona'\n",
    "    else:\n",
    "        chapter_type = 'Interlude'\n",
    "        viewpoint = perspective_or_interlude\n",
    "        print(f\"Not caught: {perspective_or_interlude}\")\n",
    "        decompose_flag = False\n",
    "\n",
    "    text = soup.body\n",
    "    text.h1.decompose()\n",
    "    if decompose_flag:\n",
    "        text.p.decompose() # First p is the interlide / viewpoint\n",
    "    clean_text = text.getText().replace(u'\\xa0', ' ').replace(u'\\n', '  ').replace(\"Next Chapter\",\"\").replace(\"Previous Chapter\",\"\")\n",
    "    # TODO Format this so it matches the text / metadata format Haystack expects\n",
    "    d = {\n",
    "        # Some of this information is going to removed in favor of the spreadsheet versions\n",
    "        'arc_title': arc_name,\n",
    "        'arc_number': arc_number,\n",
    "        'chapter_number': chapter_number,\n",
    "        'starting_viewpoint': viewpoint,\n",
    "        'chapter_type': chapter_type,\n",
    "        'text': clean_text,\n",
    "        'file_number':file_number\n",
    "    }\n",
    "    parsed_files.append(d)\n",
    "df = pd.DataFrame(parsed_files)\n",
    "df = df.drop_duplicates(subset=['arc_number','chapter_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('file_number',ascending=True)\n",
    "df['absolute_file_number'] = range(1,len(df)+1) # 1-indexed\n",
    "df['chapter'] = df['arc_number'].astype(str) + \".\" + df['chapter_number'].astype(str)\n",
    "df = df.sort_values(by='absolute_file_number', ascending=True)\n",
    "# df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arc_title</th>\n",
       "      <th>arc_number</th>\n",
       "      <th>chapter_number</th>\n",
       "      <th>starting_viewpoint</th>\n",
       "      <th>chapter_type</th>\n",
       "      <th>text</th>\n",
       "      <th>file_number</th>\n",
       "      <th>absolute_file_number</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Break</td>\n",
       "      <td>13</td>\n",
       "      <td>B1</td>\n",
       "      <td>mccauleigh sat in the chair in raymond’s offic...</td>\n",
       "      <td>Interlude</td>\n",
       "      <td>McCauleigh sat in the chair in Raymond’s off...</td>\n",
       "      <td>145</td>\n",
       "      <td>140</td>\n",
       "      <td>13.B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Break</td>\n",
       "      <td>13</td>\n",
       "      <td>B2</td>\n",
       "      <td></td>\n",
       "      <td>Interlude</td>\n",
       "      <td>Hurry up and wait.  John walked into the ...</td>\n",
       "      <td>147</td>\n",
       "      <td>142</td>\n",
       "      <td>13.B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Break</td>\n",
       "      <td>13</td>\n",
       "      <td>B3</td>\n",
       "      <td>the alabaster doe endured an existence of para...</td>\n",
       "      <td>Interlude</td>\n",
       "      <td>The Alabaster Doe endured an existence of pa...</td>\n",
       "      <td>149</td>\n",
       "      <td>144</td>\n",
       "      <td>13.B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Break</td>\n",
       "      <td>13</td>\n",
       "      <td>B4</td>\n",
       "      <td>cagerattler</td>\n",
       "      <td>Interlude</td>\n",
       "      <td>Cagerattler  Men with guns entered the Arena...</td>\n",
       "      <td>151</td>\n",
       "      <td>146</td>\n",
       "      <td>13.B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Break</td>\n",
       "      <td>13</td>\n",
       "      <td>B5</td>\n",
       "      <td>the alabaster gave the signal.</td>\n",
       "      <td>Interlude</td>\n",
       "      <td>The Alabaster gave the signal.  “We could co...</td>\n",
       "      <td>153</td>\n",
       "      <td>148</td>\n",
       "      <td>13.B5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Summer Break</td>\n",
       "      <td>13</td>\n",
       "      <td>end</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>Lucy’s phone rang.  Her shaking hands near...</td>\n",
       "      <td>154</td>\n",
       "      <td>149</td>\n",
       "      <td>13.end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        arc_title arc_number chapter_number  \\\n",
       "50          Break         13             B1   \n",
       "52          Break         13             B2   \n",
       "54          Break         13             B3   \n",
       "57          Break         13             B4   \n",
       "59          Break         13             B5   \n",
       "60   Summer Break         13            end   \n",
       "\n",
       "                                   starting_viewpoint chapter_type  \\\n",
       "50  mccauleigh sat in the chair in raymond’s offic...    Interlude   \n",
       "52                                                       Interlude   \n",
       "54  the alabaster doe endured an existence of para...    Interlude   \n",
       "57                                        cagerattler    Interlude   \n",
       "59                     the alabaster gave the signal.    Interlude   \n",
       "60                                               Lucy         Lucy   \n",
       "\n",
       "                                                 text  file_number  \\\n",
       "50    McCauleigh sat in the chair in Raymond’s off...          145   \n",
       "52       Hurry up and wait.  John walked into the ...          147   \n",
       "54    The Alabaster Doe endured an existence of pa...          149   \n",
       "57    Cagerattler  Men with guns entered the Arena...          151   \n",
       "59    The Alabaster gave the signal.  “We could co...          153   \n",
       "60      Lucy’s phone rang.  Her shaking hands near...          154   \n",
       "\n",
       "    absolute_file_number chapter  \n",
       "50                   140   13.B1  \n",
       "52                   142   13.B2  \n",
       "54                   144   13.B3  \n",
       "57                   146   13.B4  \n",
       "59                   148   13.B5  \n",
       "60                   149  13.end  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['arc_number']==13]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join in information from the [Pale Amalgram Spreadsheet](https://docs.google.com/spreadsheets/d/1VS0HRcbHChh4gmL8LcL8xiIvo-nPhSgs2OGOVV3fVbo/edit#gid=0) to get more accurate views, wordcounts, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc Number</th>\n",
       "      <th>Arc Title</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>PoV</th>\n",
       "      <th>Wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prologue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Louise</td>\n",
       "      <td>7174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arc 1</td>\n",
       "      <td>Lost for Words</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Verona</td>\n",
       "      <td>9191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>6799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Avery</td>\n",
       "      <td>9492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Avery</td>\n",
       "      <td>8616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Arc Number       Arc Title Chapter     PoV Wordcount\n",
       "0   prologue             NaN     NaN  Louise      7174\n",
       "1      arc 1  Lost for Words     1.1  Verona      9191\n",
       "2        NaN             NaN     1.2    Lucy      6799\n",
       "3        NaN             NaN     1.3   Avery      9492\n",
       "4        NaN             NaN     1.4   Avery      8616"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsheet_url = f\"https://docs.google.com/spreadsheets/d/1VS0HRcbHChh4gmL8LcL8xiIvo-nPhSgs2OGOVV3fVbo/gviz/tq?tqx=out:csv\"\n",
    "stats_dirty = pd.read_csv(gsheet_url, header=None, index_col=False,\n",
    "names=['a','b','c','Arc Number', 'Arc Title', 'Chapter','PoV','Wordcount','Synopses','Reddit Discussion', 'Audiobook Link', 'Pale Reflections Discussion', 'n','o','p','q'], \n",
    "dtype = {'Arc Number':str, 'Arc Title':str, 'Chapter':str,'PoV':str,'Wordcount':str},\n",
    "usecols = ['Arc Number', 'Arc Title', 'Chapter','PoV','Wordcount'],\n",
    "skiprows=1,\n",
    "encoding='UTF-8'\n",
    ")\n",
    "# stats_dirty = stats_dirty.drop(columns=['a','b','c','Synopses','Reddit Discussion', 'Audiobook Link', 'Pale Reflections Discussion', 'n','o','p','q'])\n",
    "# stats_dirty = stats_dirty.dropna()\n",
    "stats_dirty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc Number</th>\n",
       "      <th>Arc Title</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>PoV</th>\n",
       "      <th>Wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prologue</td>\n",
       "      <td>Blood Runs Cold</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Louise</td>\n",
       "      <td>7174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arc 1</td>\n",
       "      <td>Lost for Words</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Verona</td>\n",
       "      <td>9191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>6799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Avery</td>\n",
       "      <td>9492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Avery</td>\n",
       "      <td>8616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Arc Number        Arc Title Chapter     PoV Wordcount\n",
       "0   prologue  Blood Runs Cold     0.0  Louise      7174\n",
       "1      arc 1   Lost for Words     1.1  Verona      9191\n",
       "2        NaN              NaN     1.2    Lucy      6799\n",
       "3        NaN              NaN     1.3   Avery      9492\n",
       "4        NaN              NaN     1.4   Avery      8616"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dirty.at[0,'Arc Title'] = 'Blood Runs Cold'\n",
    "stats_dirty.at[0,'Chapter'] = '0.0'\n",
    "\n",
    "stats_dirty.at[9,'Chapter'] = \"1.z\"\n",
    "stats_dirty.at[21,'Chapter'] = \"2.z\"\n",
    "stats_dirty.at[32,'Chapter'] = \"3.z\"\n",
    "stats_dirty.at[41,'Chapter'] = \"4.x\"\n",
    "stats_dirty.at[44,'Chapter'] = \"4.10\"\n",
    "stats_dirty.at[47,'Chapter'] = \"5.a\"\n",
    "stats_dirty.at[48,'Chapter'] = \"5.b\"\n",
    "stats_dirty.at[53,'Chapter'] = \"5.c\"\n",
    "stats_dirty.at[55,'Chapter'] = \"5.d\"\n",
    "stats_dirty.at[66,'Chapter'] = \"6.z\"\n",
    "stats_dirty.at[74,'Chapter'] = \"7.a\"\n",
    "stats_dirty.at[78,'Chapter'] = \"7.x\"\n",
    "stats_dirty.at[86,'Chapter'] = \"8.a\"\n",
    "stats_dirty.at[100,'Chapter'] = \"9.10\"\n",
    "stats_dirty.at[103,'Chapter'] = \"9.z\"\n",
    "stats_dirty.at[106,'Chapter'] = \"10.a\"\n",
    "stats_dirty.at[107,'Chapter'] = \"10.b\"\n",
    "stats_dirty.at[108,'Chapter'] = \"10.c\"\n",
    "stats_dirty.at[110,'Chapter'] = \"10.d\"\n",
    "stats_dirty.at[111,'Chapter'] = \"10.e\"\n",
    "stats_dirty.at[114,'Chapter'] = \"10.z\"\n",
    "stats_dirty.at[125,'Chapter'] = \"11.10\"\n",
    "stats_dirty.at[129,'Chapter'] = \"11.z\"\n",
    "stats_dirty.at[132,'Chapter'] = \"12.aa\"\n",
    "stats_dirty.at[139,'Chapter'] = \"12.a\"\n",
    "stats_dirty.at[140,'Chapter'] = \"12.8\"\n",
    "stats_dirty.at[141,'Chapter'] = \"12.9\"\n",
    "stats_dirty.at[142,'Chapter'] = \"12.10\"\n",
    "stats_dirty.at[143,'Chapter'] = \"12.z\"\n",
    "stats_dirty.at[154,'Chapter'] = \"13.B1\"\n",
    "stats_dirty.at[155,'Chapter'] = \"13.10\"\n",
    "stats_dirty.at[156,'Chapter'] = \"13.B2\"\n",
    "stats_dirty.at[158,'Chapter'] = \"13.B3\"\n",
    "stats_dirty.at[160,'Chapter'] = \"13.B4\"\n",
    "stats_dirty.at[162,'Chapter'] = \"13.B5\"\n",
    "stats_dirty.at[163,'Chapter'] = \"13.end\"\n",
    "stats_dirty.at[165,'Chapter'] = \"14.1\"\n",
    "stats_dirty.at[171,'Chapter'] = \"14.z\"\n",
    "stats_dirty.at[182,'Chapter'] = \"15.10\"\n",
    "stats_dirty.at[184,'Chapter'] = \"15.z\"\n",
    "stats_dirty.at[195,'Chapter'] = \"16.10\"\n",
    "stats_dirty.at[196,'Chapter'] = \"16.y\"\n",
    "stats_dirty.at[197,'Chapter'] = \"16.z\"\n",
    "stats_dirty.at[206,'Chapter'] = \"17.a\"\n",
    "stats_dirty.at[207,'Chapter'] = \"17.b\"\n",
    "stats_dirty.at[210,'Chapter'] = \"17.10\"\n",
    "stats_dirty.at[216,'Chapter'] = \"17.x\"\n",
    "stats_dirty.at[217,'Chapter'] = \"17.y\"\n",
    "stats_dirty.at[218,'Chapter'] = \"17.z\"\n",
    "stats_dirty.at[222,'Chapter'] = \"18.a\"\n",
    "stats_dirty.at[226,'Chapter'] = \"18.b\"\n",
    "stats_dirty.at[229,'Chapter'] = \"18.c\"\n",
    "stats_dirty.at[232,'Chapter'] = \"18.10\"\n",
    "stats_dirty.at[233,'Chapter'] = \"18.y\"\n",
    "stats_dirty.at[234,'Chapter'] = \"18.z\"\n",
    "stats_dirty.at[245,'Chapter'] = \"19.10\"\n",
    "stats_dirty.at[246,'Chapter'] = \"19.11\"\n",
    "stats_dirty.at[247,'Chapter'] = \"19.12\"\n",
    "stats_dirty.at[248,'Chapter'] = \"19.13\"\n",
    "stats_dirty.at[249,'Chapter'] = \"19.14\"\n",
    "stats_dirty.at[250,'Chapter'] = \"19.15\"\n",
    "stats_dirty.at[251,'Chapter'] = \"19.16\"\n",
    "stats_dirty.at[252,'Chapter'] = \"19.17\"\n",
    "stats_dirty.at[253,'Chapter'] = \"19.z\"\n",
    "stats_dirty.at[258,'Chapter'] = \"20.a\"\n",
    "stats_dirty.at[262,'Chapter'] = \"20.b\"\n",
    "stats_dirty.at[263,'Chapter'] = \"20.c\"\n",
    "stats_dirty.at[264,'Chapter'] = \"20.7\"\n",
    "stats_dirty.at[265,'Chapter'] = \"20.8\"\n",
    "stats_dirty.at[266,'Chapter'] = \"20.d\"\n",
    "stats_dirty.at[267,'Chapter'] = \"20.e\"\n",
    "stats_dirty.at[268,'Chapter'] = \"20.9\"\n",
    "stats_dirty.at[269,'Chapter'] = \"20.f\"\n",
    "stats_dirty.at[270,'Chapter'] = \"20.z\"\n",
    "stats_dirty.at[281,'Chapter'] = \"21.10\"\n",
    "stats_dirty.at[282,'Chapter'] = \"21.11\"\n",
    "stats_dirty.at[283,'Chapter'] = \"21.12\"\n",
    "stats_dirty.at[284,'Chapter'] = \"21.13\"\n",
    "stats_dirty.at[285,'Chapter'] = \"21.14\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stats_dirty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsheet_url = f\"https://docs.google.com/spreadsheets/d/1tVpjBsylcCae-rW7f4ZzjLgXqJ0i_K5foQyRTTn-unk/gviz/tq?tqx=out:csv&sheet=Parseable\"\n",
    "# stats_dirty = pd.read_csv(gsheet_url, index_col=False,\n",
    "# # names=['a','b','c','Arc Number', 'Arc Title', 'Chapter','PoV','Wordcount','Synopses','Reddit Discussion', 'Audiobook Link', 'Pale Reflections Discussion', 'n','o','p','q'], \n",
    "# dtype = {'Arc Number':str, 'Arc Title':str, 'Chapter':object,'PoV':str,'Wordcount':str},\n",
    "# usecols = ['Arc Number', 'Arc Title', 'Chapter','PoV','Wordcount'],\n",
    "# # skiprows=1,\n",
    "# # encoding='UTF-8'\n",
    "# )\n",
    "# # stats_dirty = stats_dirty.drop(columns=['a','b','c','Synopses','Reddit Discussion', 'Audiobook Link', 'Pale Reflections Discussion', 'n','o','p','q'])\n",
    "# # stats_dirty = stats_dirty.dropna()\n",
    "# stats_dirty.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about manual fixes that need to happen for this to be compatible:\n",
    "- Arc Numberprologue needs to be adjusted so that the chapter is 0.0 and the Arc Title is Blood Runs cold. Something in the formatting breaks thinkg\n",
    "- Interludes generally break things like chapter, so need to correct those manually\n",
    "- There are too many files / chapters in the HTML parsed df - fix those before the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats_dirty.copy(deep=True)\n",
    "stats = stats[~pd.to_numeric(stats['Wordcount'], errors='coerce').isnull()]\n",
    "stats['Arc Number'] = stats['Arc Number'].fillna(method='ffill')\n",
    "stats['Arc Title'] = stats['Arc Title'].fillna(method='ffill')\n",
    "stats['chapter_number'] = range(1,len(stats)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get these joined together\n",
    "all_df = stats.merge(df, how='inner', left_on='Chapter', right_on='chapter', suffixes=('_stats','_parse'))\n",
    "print(len(all_df)==len(stats), max(all_df['chapter_number_stats'])==len(all_df))\n",
    "all_df['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc Title</th>\n",
       "      <th>PoV</th>\n",
       "      <th>Wordcount</th>\n",
       "      <th>chapter_number_stats</th>\n",
       "      <th>arc_number</th>\n",
       "      <th>text</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blood Runs Cold</td>\n",
       "      <td>Louise</td>\n",
       "      <td>7174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Prologue    Louise’s eyes welled with moistu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost for Words</td>\n",
       "      <td>Verona</td>\n",
       "      <td>9191</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Verona leaned over her kitchen sink, looki...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lost for Words</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>6799</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>If their job was to solve a mystery, then ...</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lost for Words</td>\n",
       "      <td>Avery</td>\n",
       "      <td>9492</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Avery and her friends sat in the back of a...</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lost for Words</td>\n",
       "      <td>Avery</td>\n",
       "      <td>8616</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Their travel plans hadn’t allowed much lee...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Arc Title     PoV Wordcount  chapter_number_stats arc_number  \\\n",
       "0  Blood Runs Cold  Louise      7174                     1          0   \n",
       "1   Lost for Words  Verona      9191                     2          1   \n",
       "2   Lost for Words    Lucy      6799                     3          1   \n",
       "3   Lost for Words   Avery      9492                     4          1   \n",
       "4   Lost for Words   Avery      8616                     5          1   \n",
       "\n",
       "                                                text chapter  \n",
       "0    Prologue    Louise’s eyes welled with moistu...     0.0  \n",
       "1      Verona leaned over her kitchen sink, looki...     1.1  \n",
       "2      If their job was to solve a mystery, then ...     1.2  \n",
       "3      Avery and her friends sat in the back of a...     1.3  \n",
       "4      Their travel plans hadn’t allowed much lee...     1.4  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now clean up the DF so that it's actually functional for something\n",
    "all_df = all_df.drop(\n",
    "    columns = ['chapter_type','file_number', 'absolute_file_number', 'Chapter', 'starting_viewpoint', 'arc_title', 'Arc Number','chapter_number_parse']\n",
    ")\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dict = all_df.to_dict(orient='index')\n",
    "chapter_construct_list = [\n",
    "    {'content':i['text'], 'meta': {\n",
    "        'arc_title': i['Arc Title'],\n",
    "        'pov': i['PoV'],\n",
    "        'wordcount': i['Wordcount'],\n",
    "        'series_chapter_number': i['chapter_number_stats'],\n",
    "        'arc_number': i['arc_number'],\n",
    "        'extra_material': False,\n",
    "        'title': i['Arc Title'] + ' - ' + i['chapter'],\n",
    "        'chapter': i['chapter'].lower() # We'll use it later as a join key\n",
    "    }}\n",
    "    for idx, i in raw_dict.items()\n",
    "    ]\n",
    "chapter_arc_lookup = {i['meta']['chapter']:i['meta'] for i in chapter_construct_list} # Use this for the extra materials -> chapter matchings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the Extra Materials (transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These were all taken manually and given the necessary information.\n",
    "dir_extra_prefix = './pale-extra-materials/'\n",
    "extra_files = sorted([f for f in os.listdir(dir_extra_prefix) if os.path.isfile(os.path.join(dir_extra_prefix,f)) and f.endswith('.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_materials = []\n",
    "for fname in extra_files:\n",
    "    # print(fname)\n",
    "    splits = re.split(r'(\\d\\.[\\d\\w]{1,2} \\w)', fname)\n",
    "    chapter_attached = splits[0] + re.split(r' ',splits[1])[0]\n",
    "    title_with_ext =  re.split(r' ',splits[1])[-1] + splits[-1]\n",
    "    title = title_with_ext.rsplit('.',1)[0]\n",
    "\n",
    "    with open(dir_extra_prefix + fname, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    d = {\n",
    "        'chapter': chapter_attached.lower(),\n",
    "        'title': title,\n",
    "        'text': data\n",
    "    }\n",
    "\n",
    "    extra_materials.append(d)\n",
    "extra_df = pd.DataFrame(extra_materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_df[['arc_title', 'pov', 'wordcount', 'series_chapter_number', 'arc_number']] = extra_df.apply(lambda x: (chapter_arc_lookup[x['chapter']]['arc_title'], 'Extra Materials', '0', chapter_arc_lookup[x['chapter']]['series_chapter_number'], chapter_arc_lookup[x['chapter']]['arc_number']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_dict = extra_df.to_dict(orient='index')\n",
    "extra_construct_list = [\n",
    "    {'content':i['text'], 'meta': {\n",
    "        'arc_title': i['arc_title'],\n",
    "        'pov': i['pov'],\n",
    "        'wordcount': i['wordcount'],\n",
    "        'series_chapter_number': i['series_chapter_number'],\n",
    "        'arc_number': i['arc_number'],\n",
    "        'title': i['title'],\n",
    "        'extra_material': True,\n",
    "        'chapter': i['chapter'].lower() # We'll use it later as a join key\n",
    "    }}\n",
    "    for idx, i in extra_dict.items()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "haystack_construct_list = chapter_construct_list + extra_construct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./chapter_fmt_list.pkl','wb') as f:\n",
    "    pickle.dump(haystack_construct_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pale-companion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b34b26ca0ede8a9f125e364d487712040961b4d4c8262639b9c1a29ec53671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
