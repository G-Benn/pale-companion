{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Comparisons\n",
    "Note: This may be run in Colab due to the GPU advantages\n",
    "\n",
    "### Process\n",
    "0. Try a few different Preprocessing steps\n",
    "    a. Word vs Sentence embeddings\n",
    "    b. Different overlaps\n",
    "    c. Different lenght (relative to the different max content length of the retreivers)\n",
    "1. Train a few different Retreiver models / generate a few different sets of embeddings on Pale. These may include:\n",
    "    a. The `vblagoje/dpr-question_encoder-single-lfqa-wiki` and `vblagoje/dpr-ctx_encoder-single-lfqa-wiki` embedders.\n",
    "    b. The `facebook/dpr-question_encoder-single-nq-base` and `facebook/dpr-ctx_encoder-single-nq-base` embedders.\n",
    "    c. The `facebook/dpr-question_encoder-multiset-base` and `facebook/dpr-ctx_encoder-multiset-base` embedders.\n",
    "    d. A fine-tuned using Pseudolabeling embedders (not created yet)\n",
    "2. Test a few different [Seq2Seq](https://huggingface.co/models?pipeline_tag=text2text-generation) models / summarization models to generate the answers. \n",
    "    a. `vblagoje/bart_lfqa`\n",
    "    b. `yjernite/bart_eli5`\n",
    "    c. Some other Seq2Seq with a [converter](https://github.com/deepset-ai/haystack/blob/f4a30a552ae47ba11f3bb2d7350cf8703a352f30/haystack/nodes/answer_generator/transformers.py#L484)\n",
    "    c. A Summarizer.\n",
    "    d. fine-tuned versions of a few different versions\n",
    "3. For each of the above combinations\n",
    "    a. Test a number of different parameters for each (top k, n beams, etc).\n",
    "    b. Generate a table of unique combinations of Retreiver, Seq2Seq/Summarizer, and parameters.\n",
    "    c. For each combinations, evaluate it on a series of 10-20 questions and note their performance. Focus on characters, situations, etc.\n",
    "    d. Choose a final 2-3 combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pale-companion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94b34b26ca0ede8a9f125e364d487712040961b4d4c8262639b9c1a29ec53671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
