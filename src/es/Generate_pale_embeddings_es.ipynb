{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Hkz5s2t0wV"
      },
      "source": [
        "Code portions:\n",
        "- All Pale chapters (through 23.1)\n",
        "- Reasonably \"optimal\" preprocessing parameters\n",
        "- fine-tuned embedding model\n",
        "- ElasticSearch container Document Store\n",
        "- Iterate and add other series embeddings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLVRRUpHxX-y",
        "outputId": "7bb07896-3115-4f45-9661-66801c02d8ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar  5 21:55:38 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 515.65.01    Driver Version: 516.94       CUDA Version: 11.7     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  ERR!                On   | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   42C    P0    N/A /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bjrm1Ei0w_Yw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "import time\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "from haystack import Document\n",
        "from haystack.nodes import PreProcessor, EmbeddingRetriever, Seq2SeqGenerator, TransformersSummarizer, FARMReader\n",
        "from haystack.pipelines import GenerativeQAPipeline, ExtractiveQAPipeline, SearchSummarizationPipeline\n",
        "from haystack.utils import launch_es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VHt2o5oJx3Xf"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.WARNING)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhzd5mpltz3f",
        "outputId": "e3ff23b4-0ffd-48c7-ecd7-13c16208c34b"
      },
      "outputs": [],
      "source": [
        "# print(os.getcwd())\n",
        "# os.chdir('./drive/MyDrive/pale-companion-files/es-experimentation/')\n",
        "\n",
        "# print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TnLqqkWEvdzn"
      },
      "outputs": [],
      "source": [
        "MODEL_LOCATION = \"../../twig_otherverse_parahumans_adapted/\"\n",
        "PALE_CHAPTERS_FNAME = \"../../data/chapter_fmt_list.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLyWxDd_wwiO",
        "outputId": "e6140548-f858-4ba6-eeec-ab537c3eee65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with 62 chapters\n"
          ]
        }
      ],
      "source": [
        "with open(PALE_CHAPTERS_FNAME,'rb') as f:\n",
        "    all_chapters = pickle.load(f)\n",
        "chapters = [i for i in all_chapters if int(i['meta']['arc_number']) < 3]\n",
        "print(f\"Testing with {len(chapters)} chapters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "50387ea05bfc48dd98f21784f583250b",
            "ab0d6d22619445769282261766939e12",
            "f9ef602f987744b4aa07e89152781032",
            "0ebdbe9bc68447928863ae2f9f2e4aac",
            "eee33b79a7604e37900262e1eaebd65f",
            "f269b10177064b1fba504402372ea96d",
            "3ba966444d6d4bf68db793b57a7e766e",
            "a7de97de7dc54574b26de2ca924eeacd",
            "f1b06ea96b6f46df9c859e73b68a7958",
            "9a0037306456470c811b2ae0baa3e9ce",
            "8a9f9990c78a4c08ac4043e69d9c82b4"
          ]
        },
        "id": "PxlS-xTOxMdt",
        "outputId": "3796c626-9524-4740-d57c-f290b3fff1c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e0644b987bf401fa9a837325f384462",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Preprocessing:   0%|          | 0/62 [00:01<?, ?docs/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We will be working with 2140 documents from 307 chapters\n"
          ]
        }
      ],
      "source": [
        "preprocessor = PreProcessor(\n",
        "    split_by='word',\n",
        "    split_length=250,\n",
        "    split_overlap=20,\n",
        "\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=True,\n",
        "    split_respect_sentence_boundary=True,\n",
        "    progress_bar=True, \n",
        "    add_page_number=True\n",
        ")\n",
        "docs = preprocessor.process(chapters)\n",
        "print(f\"We will be working with {len(docs)} documents from {len(all_chapters)} chapters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mAs_kM3Pyg5k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unable to find image 'elasticsearch:7.17.6' locally\n",
            "7.17.6: Pulling from library/elasticsearch\n",
            "3b65ec22a9e9: Pulling fs layer\n",
            "8aa839ec4bcf: Pulling fs layer\n",
            "d59e7399c065: Pulling fs layer\n",
            "aaa821b5c79a: Pulling fs layer\n",
            "6b43de0011f5: Pulling fs layer\n",
            "d0e32e747aea: Pulling fs layer\n",
            "9df7bf99d869: Pulling fs layer\n",
            "6c29c988ba57: Pulling fs layer\n",
            "c547bc2077a7: Pulling fs layer\n",
            "aaa821b5c79a: Waiting\n",
            "6b43de0011f5: Waiting\n",
            "d0e32e747aea: Waiting\n",
            "9df7bf99d869: Waiting\n",
            "6c29c988ba57: Waiting\n",
            "c547bc2077a7: Waiting\n",
            "d59e7399c065: Verifying Checksum\n",
            "d59e7399c065: Download complete\n",
            "8aa839ec4bcf: Verifying Checksum\n",
            "8aa839ec4bcf: Download complete\n",
            "6b43de0011f5: Verifying Checksum\n",
            "6b43de0011f5: Download complete\n",
            "3b65ec22a9e9: Verifying Checksum\n",
            "3b65ec22a9e9: Download complete\n",
            "d0e32e747aea: Verifying Checksum\n",
            "d0e32e747aea: Download complete\n",
            "9df7bf99d869: Verifying Checksum\n",
            "9df7bf99d869: Download complete\n",
            "6c29c988ba57: Verifying Checksum\n",
            "6c29c988ba57: Download complete\n",
            "c547bc2077a7: Verifying Checksum\n",
            "c547bc2077a7: Download complete\n",
            "3b65ec22a9e9: Pull complete\n",
            "8aa839ec4bcf: Pull complete\n",
            "d59e7399c065: Pull complete\n",
            "aaa821b5c79a: Verifying Checksum\n",
            "aaa821b5c79a: Download complete\n",
            "aaa821b5c79a: Pull complete\n",
            "6b43de0011f5: Pull complete\n",
            "d0e32e747aea: Pull complete\n",
            "9df7bf99d869: Pull complete\n",
            "6c29c988ba57: Pull complete\n",
            "c547bc2077a7: Pull complete\n",
            "Digest: sha256:6c128de5d01c0c130a806022d6bd99b3e4c27a9af5bfc33b6b81861ae117d028\n",
            "Status: Downloaded newer image for elasticsearch:7.17.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b0baf7f0328c2d49b6e0281de3cba8d45a5aa9471ca5ee17bd5c37572c796804\n"
          ]
        }
      ],
      "source": [
        "# Recommended: Start Elasticsearch using Docker via the Haystack utility function\n",
        "# from haystack.utils import launch_es\n",
        "# This is what we would use if we're outside of Colab - instead we have to do something else\n",
        "launch_es()\n",
        "time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fd5_0GGgyyhD",
        "outputId": "cd529777-2f3a-43be-f9c8-bc72c10e2dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "localhost\n"
          ]
        }
      ],
      "source": [
        "# Get the host where Elasticsearch is running, default to localhost\n",
        "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
        "print(host)\n",
        "\n",
        "document_store = ElasticsearchDocumentStore(\n",
        "    host=host,\n",
        "    username=\"\",\n",
        "    password=\"\",\n",
        "    index=\"pale_index\",\n",
        "    embedding_field=\"emb\",\n",
        "    embedding_dim=768,\n",
        "    excluded_meta_data=[\"emb\"],\n",
        ")\n",
        "\n",
        "document_store.write_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "h1hVO1qhzhdG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n",
            "INFO:haystack.nodes.retriever.dense:Init retriever using embeddings of model ../twig_otherverse_parahumans_adapted\n"
          ]
        },
        {
          "ename": "HFValidationError",
          "evalue": "Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '../twig_otherverse_parahumans_adapted'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever \u001b[39m=\u001b[39m EmbeddingRetriever(\n\u001b[1;32m      2\u001b[0m     document_store\u001b[39m=\u001b[39;49mdocument_store,\n\u001b[1;32m      3\u001b[0m     embedding_model\u001b[39m=\u001b[39;49mMODEL_LOCATION,\n\u001b[1;32m      4\u001b[0m     model_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msentence_transformers\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     max_seq_len\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m     10\u001b[0m document_store\u001b[39m.\u001b[39mupdate_embeddings(retriever)\n",
            "File \u001b[0;32m~/pale-companion/pale-companion/lib/python3.10/site-packages/haystack/nodes/base.py:48\u001b[0m, in \u001b[0;36mexportable_to_yaml.<locals>.wrapper_exportable_to_yaml\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_component_config[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m][k] \u001b[39m=\u001b[39m v\n\u001b[1;32m     47\u001b[0m \u001b[39m# Call the actuall __init__ function with all the arguments\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m init_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/pale-companion/pale-companion/lib/python3.10/site-packages/haystack/nodes/retriever/dense.py:1545\u001b[0m, in \u001b[0;36mEmbeddingRetriever.__init__\u001b[0;34m(self, embedding_model, document_store, model_version, use_gpu, batch_size, max_seq_len, model_format, pooling_strategy, emb_extraction_layer, top_k, progress_bar, devices, use_auth_token, scale_score, embed_meta_fields, api_key)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1533\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39msentence-transformers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1534\u001b[0m     \u001b[39mand\u001b[39;00m model_format\n\u001b[1;32m   1535\u001b[0m     \u001b[39mand\u001b[39;00m model_format \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msentence_transformers\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1536\u001b[0m ):\n\u001b[1;32m   1537\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   1538\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou seem to be using a Sentence Transformer embedding model but \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_format\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is set to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1539\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m You may need to set model_format=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msentence_transformers\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to ensure correct loading of model.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_format,\n\u001b[1;32m   1543\u001b[0m     )\n\u001b[0;32m-> 1545\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_encoder \u001b[39m=\u001b[39m _EMBEDDING_ENCODERS[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_format](retriever\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1546\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_meta_fields \u001b[39m=\u001b[39m embed_meta_fields\n",
            "File \u001b[0;32m~/pale-companion/pale-companion/lib/python3.10/site-packages/haystack/nodes/retriever/_embedding_encoder.py:108\u001b[0m, in \u001b[0;36m_SentenceTransformersEmbeddingEncoder.__init__\u001b[0;34m(self, retriever)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mhaystack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m _optional_component_not_installed\n\u001b[1;32m    106\u001b[0m     _optional_component_not_installed(\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m\"\u001b[39m, ie)\n\u001b[0;32m--> 108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m SentenceTransformer(\n\u001b[1;32m    109\u001b[0m     retriever\u001b[39m.\u001b[39;49membedding_model, device\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(retriever\u001b[39m.\u001b[39;49mdevices[\u001b[39m0\u001b[39;49m]), use_auth_token\u001b[39m=\u001b[39;49mretriever\u001b[39m.\u001b[39;49muse_auth_token\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m retriever\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39mmax_seq_length \u001b[39m=\u001b[39m retriever\u001b[39m.\u001b[39mmax_seq_len\n",
            "File \u001b[0;32m~/pale-companion/pale-companion/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:87\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     83\u001b[0m     model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m     86\u001b[0m         \u001b[39m# Download from hub with caching\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[1;32m     88\u001b[0m                             cache_dir\u001b[39m=\u001b[39;49mcache_folder,\n\u001b[1;32m     89\u001b[0m                             library_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msentence-transformers\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     90\u001b[0m                             library_version\u001b[39m=\u001b[39;49m__version__,\n\u001b[1;32m     91\u001b[0m                             ignore_files\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mflax_model.msgpack\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrust_model.ot\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtf_model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     92\u001b[0m                             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token)\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):    \u001b[39m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_sbert_model(model_path)\n",
            "File \u001b[0;32m~/pale-companion/pale-companion/lib/python3.10/site-packages/sentence_transformers/util.py:442\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39melif\u001b[39;00m use_auth_token:\n\u001b[1;32m    440\u001b[0m     token \u001b[39m=\u001b[39m HfFolder\u001b[39m.\u001b[39mget_token()\n\u001b[0;32m--> 442\u001b[0m model_info \u001b[39m=\u001b[39m _api\u001b[39m.\u001b[39;49mmodel_info(repo_id\u001b[39m=\u001b[39;49mrepo_id, revision\u001b[39m=\u001b[39;49mrevision, token\u001b[39m=\u001b[39;49mtoken)\n\u001b[1;32m    444\u001b[0m storage_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    445\u001b[0m     cache_dir, repo_id\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    446\u001b[0m )\n\u001b[1;32m    448\u001b[0m all_files \u001b[39m=\u001b[39m model_info\u001b[39m.\u001b[39msiblings\n",
            "File \u001b[0;32m~/pale-companion/pale-companion/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[1;32m    110\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[1;32m    112\u001b[0m ):\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m    116\u001b[0m     \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         has_token \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/pale-companion/pale-companion/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:172\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    167\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m--\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id:\n\u001b[1;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot have -- or .. in repo_id: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '../twig_otherverse_parahumans_adapted'."
          ]
        }
      ],
      "source": [
        "retriever = EmbeddingRetriever(\n",
        "    document_store=document_store,\n",
        "    embedding_model=MODEL_LOCATION,\n",
        "    model_format=\"sentence_transformers\",\n",
        "    max_seq_len=500,\n",
        "    progress_bar=True,\n",
        ")\n",
        "\n",
        "\n",
        "document_store.update_embeddings(retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VsxGUte0Bgg"
      },
      "outputs": [],
      "source": [
        "generator = Seq2SeqGenerator(model_name_or_path=\"vblagoje/bart_lfqa\", num_beams=8, max_length=500)\n",
        "# Eventually with want to tweak the above\n",
        "pipe = GenerativeQAPipeline(generator, retriever) # We specify the params later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q4NIiZW0ZJH"
      },
      "outputs": [],
      "source": [
        "TEST_QUESTION = \"Who is Avery Kelly?\"\n",
        "\n",
        "TEST_OUTPUT = pipe.run(\n",
        "                query = TEST_QUESTION,\n",
        "                params = {\n",
        "                    \"Retriever\": {\"top_k\":10},\n",
        "                    # \"Generator\": {\"max_length\": maxlength, \"num_beams\": nbeam}\n",
        "                }\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_OUTPUT"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pale-companion",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "94b34b26ca0ede8a9f125e364d487712040961b4d4c8262639b9c1a29ec53671"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ebdbe9bc68447928863ae2f9f2e4aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a0037306456470c811b2ae0baa3e9ce",
            "placeholder": "​",
            "style": "IPY_MODEL_8a9f9990c78a4c08ac4043e69d9c82b4",
            "value": " 307/307 [00:24&lt;00:00, 61.18docs/s]"
          }
        },
        "3ba966444d6d4bf68db793b57a7e766e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50387ea05bfc48dd98f21784f583250b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab0d6d22619445769282261766939e12",
              "IPY_MODEL_f9ef602f987744b4aa07e89152781032",
              "IPY_MODEL_0ebdbe9bc68447928863ae2f9f2e4aac"
            ],
            "layout": "IPY_MODEL_eee33b79a7604e37900262e1eaebd65f"
          }
        },
        "8a9f9990c78a4c08ac4043e69d9c82b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a0037306456470c811b2ae0baa3e9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7de97de7dc54574b26de2ca924eeacd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0d6d22619445769282261766939e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f269b10177064b1fba504402372ea96d",
            "placeholder": "​",
            "style": "IPY_MODEL_3ba966444d6d4bf68db793b57a7e766e",
            "value": "Preprocessing: 100%"
          }
        },
        "eee33b79a7604e37900262e1eaebd65f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b06ea96b6f46df9c859e73b68a7958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f269b10177064b1fba504402372ea96d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ef602f987744b4aa07e89152781032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7de97de7dc54574b26de2ca924eeacd",
            "max": 307,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1b06ea96b6f46df9c859e73b68a7958",
            "value": 307
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
